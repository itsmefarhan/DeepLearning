{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7XZa20yp9Bvy",
    "outputId": "5433d47d-69f6-442e-f834-f6771a073b1a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYSvXAqB9dg0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/kc_housing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "3kgzXHV898V6",
    "outputId": "694c6919-0324-4736-9786-f4657a271ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xk9nqH8U9-HF",
    "outputId": "da9e3eb6-7e43-44bc-f936-cd76a192f39f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "rOkts9o5-BFp",
    "outputId": "969bf80f-52be-410a-d66d-689b968a6b53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1VDnlCAI-KBa",
    "outputId": "79614562-424a-4bf6-be8f-85e87ba7ed45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('id', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mSzFqPNj-ZgB",
    "outputId": "76931f2a-8fa8-4b7e-9e9a-1ab6c8198b66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
       "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
       "       'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3hk9UIpF_q4x",
    "outputId": "9b2bdf3c-1942-431d-ebe3-39df532460b1"
   },
   "outputs": [],
   "source": [
    "df = df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "oU7DLT3T_543",
    "outputId": "baa2458f-c19d-4a0b-8f73-a3c77ffb7c9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00000e+00,  1.00000e+00,  1.18000e+03, ..., -1.22257e+02,\n",
       "         1.34000e+03,  5.65000e+03],\n",
       "       [ 3.00000e+00,  2.25000e+00,  2.57000e+03, ..., -1.22319e+02,\n",
       "         1.69000e+03,  7.63900e+03],\n",
       "       [ 2.00000e+00,  1.00000e+00,  7.70000e+02, ..., -1.22233e+02,\n",
       "         2.72000e+03,  8.06200e+03],\n",
       "       ...,\n",
       "       [ 2.00000e+00,  7.50000e-01,  1.02000e+03, ..., -1.22299e+02,\n",
       "         1.02000e+03,  2.00700e+03],\n",
       "       [ 3.00000e+00,  2.50000e+00,  1.60000e+03, ..., -1.22069e+02,\n",
       "         1.41000e+03,  1.28700e+03],\n",
       "       [ 2.00000e+00,  7.50000e-01,  1.02000e+03, ..., -1.22299e+02,\n",
       "         1.02000e+03,  1.35700e+03]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('price', axis=1).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sGdo_nzGCAGa",
    "outputId": "28699053-f442-4919-dabf-3997443b44de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oZQcAIPBADSa",
    "outputId": "6ba4bec1-3915-4486-ad8e-559aa184f0cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['price'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLONUkqiAZ9C"
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-p22XnYAl1q"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrtT40knAw2T"
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmBV5UPVA8AZ"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssMhVUakA905"
   },
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hukYLskEC2C2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep8kvapgDKRK"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o956WHI0Djhf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "od3EpWoBDsrK"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OBqLWV_DD6b4",
    "outputId": "e46fd66d-1e9e-469e-8876-599367e7336d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15129 samples, validate on 6484 samples\n",
      "Epoch 1/1000\n",
      "15129/15129 [==============================] - 1s 86us/sample - loss: 419663075141.3259 - val_loss: 442087711301.1721\n",
      "Epoch 2/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 418919668244.4069 - val_loss: 440360082076.3480\n",
      "Epoch 3/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 415549377525.5089 - val_loss: 434801046749.7297\n",
      "Epoch 4/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 407489225093.3217 - val_loss: 423677258858.7587\n",
      "Epoch 5/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 393508042908.0806 - val_loss: 405903401733.2117\n",
      "Epoch 6/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 372786028598.6891 - val_loss: 381199484820.6096\n",
      "Epoch 7/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 345629452342.5538 - val_loss: 350141713590.5638\n",
      "Epoch 8/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 313207199456.6113 - val_loss: 314120207737.1302\n",
      "Epoch 9/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 277182975139.8644 - val_loss: 275447061289.8507\n",
      "Epoch 10/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 239517411711.7716 - val_loss: 236895797591.6496\n",
      "Epoch 11/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 204190094167.8038 - val_loss: 201292834592.3751\n",
      "Epoch 12/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 173030059822.1778 - val_loss: 170857198955.2326\n",
      "Epoch 13/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 148581831607.6452 - val_loss: 147248419056.0493\n",
      "Epoch 14/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 131222791725.6532 - val_loss: 130468519375.0426\n",
      "Epoch 15/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 120442363231.2153 - val_loss: 119842961181.8482\n",
      "Epoch 16/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 113099242694.7896 - val_loss: 113534542091.8445\n",
      "Epoch 17/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 109110480898.9781 - val_loss: 109806873696.6514\n",
      "Epoch 18/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 107986456973.7146 - val_loss: 107579787449.7224\n",
      "Epoch 19/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 108117794400.9582 - val_loss: 106362051784.2517\n",
      "Epoch 20/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 105874733161.1818 - val_loss: 105369183173.2511\n",
      "Epoch 21/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 105991238109.3116 - val_loss: 104624654926.0160\n",
      "Epoch 22/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 103574105497.4240 - val_loss: 103898446638.9044\n",
      "Epoch 23/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 104945344004.6364 - val_loss: 103374307166.2825\n",
      "Epoch 24/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 104343171240.6700 - val_loss: 102701637131.6866\n",
      "Epoch 25/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 102799611626.6286 - val_loss: 102070711143.7582\n",
      "Epoch 26/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 104007023640.4341 - val_loss: 101455272493.1672\n",
      "Epoch 27/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 102250046813.7262 - val_loss: 100835455554.6453\n",
      "Epoch 28/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 101534985595.1013 - val_loss: 100162856554.4429\n",
      "Epoch 29/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 102008399362.6059 - val_loss: 99561514774.2677\n",
      "Epoch 30/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 100788771892.3202 - val_loss: 98899795760.7995\n",
      "Epoch 31/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 100395423136.0571 - val_loss: 98205722572.1999\n",
      "Epoch 32/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 100707767810.6059 - val_loss: 97612499817.0216\n",
      "Epoch 33/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 98461788516.9685 - val_loss: 96865958136.8933\n",
      "Epoch 34/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 97406779534.6791 - val_loss: 96149754975.3880\n",
      "Epoch 35/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 98589292518.1445 - val_loss: 95388592258.1320\n",
      "Epoch 36/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 95934580346.8137 - val_loss: 94654806082.9611\n",
      "Epoch 37/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 96771786992.0095 - val_loss: 94054535034.0777\n",
      "Epoch 38/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 95286556606.8874 - val_loss: 93170295617.8557\n",
      "Epoch 39/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 95220149595.9664 - val_loss: 92412634214.9685\n",
      "Epoch 40/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 94479967595.8046 - val_loss: 91576815219.2869\n",
      "Epoch 41/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 94000933322.4953 - val_loss: 90857456808.6662\n",
      "Epoch 42/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 93312814518.3930 - val_loss: 90042514738.3788\n",
      "Epoch 43/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 92892523343.4109 - val_loss: 89349448382.4602\n",
      "Epoch 44/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 91874820041.8523 - val_loss: 88513270202.1962\n",
      "Epoch 45/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 90088343645.5401 - val_loss: 87675313887.9408\n",
      "Epoch 46/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 89769259010.4366 - val_loss: 86964354283.6274\n",
      "Epoch 47/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 89427085470.5173 - val_loss: 86072078065.6286\n",
      "Epoch 48/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 89238362321.1454 - val_loss: 85291255387.2819\n",
      "Epoch 49/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 89470446091.4725 - val_loss: 84510953226.8970\n",
      "Epoch 50/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 86013346284.2023 - val_loss: 83606425435.7557\n",
      "Epoch 51/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 87980432297.4314 - val_loss: 82886040685.2856\n",
      "Epoch 52/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 85960890194.3214 - val_loss: 82027038572.1801\n",
      "Epoch 53/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 85141494026.2711 - val_loss: 81225220742.8698\n",
      "Epoch 54/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 84712406016.0677 - val_loss: 80395573198.7267\n",
      "Epoch 55/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 82375650739.1441 - val_loss: 79676134879.4670\n",
      "Epoch 56/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 83353383017.8587 - val_loss: 78814573446.0802\n",
      "Epoch 57/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 83057111742.0244 - val_loss: 77886584464.3455\n",
      "Epoch 58/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 82052753815.0551 - val_loss: 77132301298.7341\n",
      "Epoch 59/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 80499246275.1346 - val_loss: 76295576422.4948\n",
      "Epoch 60/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 81071448246.4776 - val_loss: 75553350920.6860\n",
      "Epoch 61/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 77740016160.5901 - val_loss: 74661981199.7927\n",
      "Epoch 62/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 77912088962.6143 - val_loss: 73908119965.1376\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 0s 31us/sample - loss: 76898249132.4434 - val_loss: 73274776836.8957\n",
      "Epoch 64/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 77989481005.0441 - val_loss: 72483245380.0666\n",
      "Epoch 65/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 77674080803.8390 - val_loss: 71756694979.6718\n",
      "Epoch 66/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 76383086343.4622 - val_loss: 71029508686.0160\n",
      "Epoch 67/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 76361896463.6690 - val_loss: 70258581357.4436\n",
      "Epoch 68/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 73858204515.1748 - val_loss: 69513175388.7033\n",
      "Epoch 69/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 74151337216.9984 - val_loss: 68777058632.4886\n",
      "Epoch 70/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 74839537439.9640 - val_loss: 68115719897.6237\n",
      "Epoch 71/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 72112827173.0404 - val_loss: 67535330564.8957\n",
      "Epoch 72/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 73150856808.8096 - val_loss: 66897132567.3732\n",
      "Epoch 73/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 72534692222.1471 - val_loss: 66236818767.4374\n",
      "Epoch 74/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 70226977201.1813 - val_loss: 65543357568.2369\n",
      "Epoch 75/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 72444410368.6430 - val_loss: 65091914974.9932\n",
      "Epoch 76/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 70441792055.1968 - val_loss: 64495577485.9766\n",
      "Epoch 77/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 71399374474.3811 - val_loss: 63989728470.1493\n",
      "Epoch 78/1000\n",
      "15129/15129 [==============================] - 1s 46us/sample - loss: 69598833984.0804 - val_loss: 63544365548.7329\n",
      "Epoch 79/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 68535861018.4139 - val_loss: 62949549113.4855\n",
      "Epoch 80/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 67089218686.7732 - val_loss: 62379963295.3485\n",
      "Epoch 81/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 67823696149.6421 - val_loss: 62018794176.9870\n",
      "Epoch 82/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 68339978279.6632 - val_loss: 61437856657.4510\n",
      "Epoch 83/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 68463529714.0739 - val_loss: 61052103104.5133\n",
      "Epoch 84/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 67873807307.5444 - val_loss: 60535203879.1659\n",
      "Epoch 85/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 67074430469.3132 - val_loss: 60077577892.5602\n",
      "Epoch 86/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 67391468518.4152 - val_loss: 59667698374.0407\n",
      "Epoch 87/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 67428941776.8915 - val_loss: 59424226878.2233\n",
      "Epoch 88/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 66415107672.5653 - val_loss: 59054842305.7767\n",
      "Epoch 89/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 65404256488.2935 - val_loss: 58563967947.5682\n",
      "Epoch 90/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 64456716809.4420 - val_loss: 58177367232.6712\n",
      "Epoch 91/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 65731989418.3113 - val_loss: 58009405489.2733\n",
      "Epoch 92/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 64837422092.7924 - val_loss: 57632815378.1616\n",
      "Epoch 93/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 63649631320.3284 - val_loss: 57387979583.3288\n",
      "Epoch 94/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 65081621347.3102 - val_loss: 57039416244.8267\n",
      "Epoch 95/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 62292309129.0613 - val_loss: 56900069819.4596\n",
      "Epoch 96/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 64180235909.2371 - val_loss: 56627191833.2684\n",
      "Epoch 97/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 63461375211.8808 - val_loss: 56294315628.9698\n",
      "Epoch 98/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 64100589260.7120 - val_loss: 56077605587.9383\n",
      "Epoch 99/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 62785345916.7934 - val_loss: 55745126344.4096\n",
      "Epoch 100/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 63115560526.1418 - val_loss: 55488232082.2406\n",
      "Epoch 101/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 63273388492.6612 - val_loss: 55414607060.8859\n",
      "Epoch 102/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 62869082287.3031 - val_loss: 55051719386.2554\n",
      "Epoch 103/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 60921600525.6384 - val_loss: 54888300124.5453\n",
      "Epoch 104/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 62011341080.6203 - val_loss: 54596176542.8748\n",
      "Epoch 105/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 61947331199.2132 - val_loss: 54438747568.7206\n",
      "Epoch 106/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 61263663819.2906 - val_loss: 54296546430.9735\n",
      "Epoch 107/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 62375129439.6891 - val_loss: 54202167657.3374\n",
      "Epoch 108/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 61397569096.5917 - val_loss: 54057399497.5151\n",
      "Epoch 109/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 60449483007.1709 - val_loss: 53716085154.1912\n",
      "Epoch 110/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 60324012774.9059 - val_loss: 53508615113.0413\n",
      "Epoch 111/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 60834914257.4330 - val_loss: 53596135282.4972\n",
      "Epoch 112/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 62196726645.4497 - val_loss: 53369918973.7890\n",
      "Epoch 113/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 60207074048.2200 - val_loss: 53106649799.3041\n",
      "Epoch 114/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 60143866948.6999 - val_loss: 52940922581.8334\n",
      "Epoch 115/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 61229196231.4834 - val_loss: 52970861122.6453\n",
      "Epoch 116/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 61857965662.7923 - val_loss: 52889487722.6009\n",
      "Epoch 117/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 60887715475.5862 - val_loss: 52613508844.5750\n",
      "Epoch 118/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 60675443217.8349 - val_loss: 52451418672.9574\n",
      "Epoch 119/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 60380567270.8383 - val_loss: 52425859526.8304\n",
      "Epoch 120/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 61372405373.2503 - val_loss: 52229923619.5336\n",
      "Epoch 121/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59743748988.8950 - val_loss: 52122448218.1764\n",
      "Epoch 122/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59992488460.2848 - val_loss: 51987479529.8902\n",
      "Epoch 123/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59583986484.2017 - val_loss: 51778433885.6508\n",
      "Epoch 124/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 59558685706.8972 - val_loss: 51828416749.5225\n",
      "Epoch 125/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59889565339.3023 - val_loss: 51622254583.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 59817775062.0356 - val_loss: 51584005205.2807\n",
      "Epoch 127/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 58280673163.5825 - val_loss: 51446760550.9685\n",
      "Epoch 128/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59118116310.6109 - val_loss: 51339230756.9550\n",
      "Epoch 129/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 58546550408.8921 - val_loss: 51397847478.4059\n",
      "Epoch 130/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 59352659116.3926 - val_loss: 51173189974.3862\n",
      "Epoch 131/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 59733522377.1755 - val_loss: 51076311417.7619\n",
      "Epoch 132/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 58659740467.2542 - val_loss: 50975805806.3911\n",
      "Epoch 133/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58840643992.6795 - val_loss: 50877447848.3504\n",
      "Epoch 134/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58613846487.7615 - val_loss: 50783756116.1752\n",
      "Epoch 135/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 58158708543.6404 - val_loss: 50729602331.6373\n",
      "Epoch 136/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 59225244951.8757 - val_loss: 50596711161.8408\n",
      "Epoch 137/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 57607578475.0262 - val_loss: 50485854329.2881\n",
      "Epoch 138/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58150912507.6343 - val_loss: 50567487028.1160\n",
      "Epoch 139/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 57268198597.1652 - val_loss: 50373171448.8933\n",
      "Epoch 140/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 56631652031.4458 - val_loss: 50372081842.1419\n",
      "Epoch 141/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 57138568013.3804 - val_loss: 50160577809.5299\n",
      "Epoch 142/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 56824811083.1637 - val_loss: 50075600829.0389\n",
      "Epoch 143/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 57542713364.7115 - val_loss: 50011074704.0296\n",
      "Epoch 144/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 57938590936.6583 - val_loss: 50078810187.8051\n",
      "Epoch 145/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 58630255631.0937 - val_loss: 49974464115.2869\n",
      "Epoch 146/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58805345582.2116 - val_loss: 49959893963.5682\n",
      "Epoch 147/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 58793630575.6288 - val_loss: 49775677765.9618\n",
      "Epoch 148/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 58829323531.0157 - val_loss: 49727202452.4516\n",
      "Epoch 149/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 57901056287.5241 - val_loss: 49694070416.3455\n",
      "Epoch 150/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 57159737585.6339 - val_loss: 49598114265.7816\n",
      "Epoch 151/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 59429595301.8272 - val_loss: 49670227340.0814\n",
      "Epoch 152/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55027148206.6770 - val_loss: 49423248950.6428\n",
      "Epoch 153/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58517087994.8729 - val_loss: 49395939147.3313\n",
      "Epoch 154/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58129504760.7916 - val_loss: 49379447024.0494\n",
      "Epoch 155/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 58672484363.3710 - val_loss: 49152428985.8803\n",
      "Epoch 156/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55822901448.8878 - val_loss: 49270889323.5484\n",
      "Epoch 157/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 57755767360.9434 - val_loss: 49158992354.6255\n",
      "Epoch 158/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 57083731136.8334 - val_loss: 49110727420.3677\n",
      "Epoch 159/1000\n",
      "15129/15129 [==============================] - 1s 48us/sample - loss: 56819530180.8098 - val_loss: 49043538076.6638\n",
      "Epoch 160/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 57948532741.1440 - val_loss: 49031675206.5935\n",
      "Epoch 161/1000\n",
      "15129/15129 [==============================] - 1s 42us/sample - loss: 56149054859.2103 - val_loss: 48885365737.8902\n",
      "Epoch 162/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 55776698501.2033 - val_loss: 48822976264.3701\n",
      "Epoch 163/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 57993106876.2139 - val_loss: 48870390655.7631\n",
      "Epoch 164/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 56890256016.9465 - val_loss: 48870036418.7242\n",
      "Epoch 165/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 56002953774.1270 - val_loss: 48682083016.5676\n",
      "Epoch 166/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 56431434051.6677 - val_loss: 48704372124.5059\n",
      "Epoch 167/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 57815842258.5498 - val_loss: 48637427247.0623\n",
      "Epoch 168/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 57535795931.2642 - val_loss: 48694407387.8347\n",
      "Epoch 169/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 56743431706.1601 - val_loss: 48555618508.6737\n",
      "Epoch 170/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 55949318336.3596 - val_loss: 48486883863.6891\n",
      "Epoch 171/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55839722903.5289 - val_loss: 48317577161.6730\n",
      "Epoch 172/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 57339267892.6078 - val_loss: 48425487421.2758\n",
      "Epoch 173/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 56513378322.6809 - val_loss: 48442131705.5250\n",
      "Epoch 174/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 54782927112.7821 - val_loss: 48260827362.1518\n",
      "Epoch 175/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55447747887.8361 - val_loss: 48282262996.0962\n",
      "Epoch 176/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 57124812790.3888 - val_loss: 48190736231.1265\n",
      "Epoch 177/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 55089607097.8449 - val_loss: 48206541045.1030\n",
      "Epoch 178/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 56287586351.2438 - val_loss: 48157153089.2239\n",
      "Epoch 179/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 55948013862.8340 - val_loss: 48128538999.2350\n",
      "Epoch 180/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55873556066.0411 - val_loss: 48057370066.8328\n",
      "Epoch 181/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55716425948.7871 - val_loss: 48069085763.9087\n",
      "Epoch 182/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 56896973977.8470 - val_loss: 47962558082.4479\n",
      "Epoch 183/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 56218643500.6041 - val_loss: 47815256906.6996\n",
      "Epoch 184/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54715393476.3360 - val_loss: 47970496256.7896\n",
      "Epoch 185/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54691941297.5536 - val_loss: 47910638566.0999\n",
      "Epoch 186/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53352056136.8794 - val_loss: 47913232883.0500\n",
      "Epoch 187/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55175472563.2795 - val_loss: 47871835482.8081\n",
      "Epoch 188/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 35us/sample - loss: 55476728609.6562 - val_loss: 47886259275.1733\n",
      "Epoch 189/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55388036862.2571 - val_loss: 47861494313.3769\n",
      "Epoch 190/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54703420852.3625 - val_loss: 47663791824.7798\n",
      "Epoch 191/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 56306074198.8732 - val_loss: 47844475536.9772\n",
      "Epoch 192/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 55488812620.7882 - val_loss: 47635960007.6200\n",
      "Epoch 193/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54273682885.0129 - val_loss: 47576828327.2449\n",
      "Epoch 194/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55340201436.1610 - val_loss: 47678473637.3498\n",
      "Epoch 195/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 56280862966.6426 - val_loss: 47562465734.8304\n",
      "Epoch 196/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55106189625.9211 - val_loss: 47589788551.3436\n",
      "Epoch 197/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 54799043105.4023 - val_loss: 47436989204.3726\n",
      "Epoch 198/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 54034407026.8269 - val_loss: 47448497230.9636\n",
      "Epoch 199/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55679183139.1791 - val_loss: 47527710328.3405\n",
      "Epoch 200/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54721680854.4755 - val_loss: 47450624886.9192\n",
      "Epoch 201/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53314246565.4380 - val_loss: 47444723963.4201\n",
      "Epoch 202/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 54930866407.7520 - val_loss: 47403599501.8186\n",
      "Epoch 203/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54744271980.0923 - val_loss: 47302451892.3529\n",
      "Epoch 204/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 53482752657.7587 - val_loss: 47356403039.8618\n",
      "Epoch 205/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55663124637.2990 - val_loss: 47390059667.1882\n",
      "Epoch 206/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55713964393.5710 - val_loss: 47281086615.6101\n",
      "Epoch 207/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 57060605383.9910 - val_loss: 47176971283.5830\n",
      "Epoch 208/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55148153388.5026 - val_loss: 47281878470.1986\n",
      "Epoch 209/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 55013658075.2134 - val_loss: 47132470596.0666\n",
      "Epoch 210/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55697752763.4524 - val_loss: 47228425660.0913\n",
      "Epoch 211/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 56846033977.3288 - val_loss: 47165352419.8890\n",
      "Epoch 212/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 56002286035.5651 - val_loss: 47117025158.7119\n",
      "Epoch 213/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 54160781058.8597 - val_loss: 47012460792.8933\n",
      "Epoch 214/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55818875552.7847 - val_loss: 47004443437.6410\n",
      "Epoch 215/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54726153180.1949 - val_loss: 47054364606.3023\n",
      "Epoch 216/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 53686933243.1436 - val_loss: 46955845249.1845\n",
      "Epoch 217/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54463892633.3056 - val_loss: 47011757008.6218\n",
      "Epoch 218/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54598372014.9985 - val_loss: 46907422923.4102\n",
      "Epoch 219/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 56711475812.4101 - val_loss: 46948385111.6496\n",
      "Epoch 220/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54596238366.2550 - val_loss: 46890665563.2819\n",
      "Epoch 221/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 55067788427.0918 - val_loss: 46837008984.1234\n",
      "Epoch 222/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 55059623496.8624 - val_loss: 46816814910.6971\n",
      "Epoch 223/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54863313321.7360 - val_loss: 46891967894.1888\n",
      "Epoch 224/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55027127871.2512 - val_loss: 46817371511.8667\n",
      "Epoch 225/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 54338540541.2249 - val_loss: 46786847447.7286\n",
      "Epoch 226/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 56113865419.0199 - val_loss: 46725480816.9179\n",
      "Epoch 227/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 54313934460.8442 - val_loss: 46721877443.6718\n",
      "Epoch 228/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 54066207121.7757 - val_loss: 46777573992.5478\n",
      "Epoch 229/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54397758241.3854 - val_loss: 46674657704.5083\n",
      "Epoch 230/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 54026180941.9557 - val_loss: 46692496838.1986\n",
      "Epoch 231/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 55245986460.1822 - val_loss: 46639558132.9451\n",
      "Epoch 232/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 55413322715.9241 - val_loss: 46594307516.0913\n",
      "Epoch 233/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55461494001.2955 - val_loss: 46551542127.6545\n",
      "Epoch 234/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 55273417449.4780 - val_loss: 46462364258.2307\n",
      "Epoch 235/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53940606870.8182 - val_loss: 46533929479.2646\n",
      "Epoch 236/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 53529756862.2614 - val_loss: 46406687196.3084\n",
      "Epoch 237/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 53925176380.1716 - val_loss: 46602535493.1721\n",
      "Epoch 238/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 54140844494.5564 - val_loss: 46443159587.3757\n",
      "Epoch 239/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 55325838840.4532 - val_loss: 46396248743.7187\n",
      "Epoch 240/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 52814849848.6012 - val_loss: 46540915698.7341\n",
      "Epoch 241/1000\n",
      "15129/15129 [==============================] - 1s 44us/sample - loss: 53634255264.5309 - val_loss: 46299306945.4608\n",
      "Epoch 242/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 55610627261.7199 - val_loss: 46391715631.5361\n",
      "Epoch 243/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 54176945549.6469 - val_loss: 46319794050.9217\n",
      "Epoch 244/1000\n",
      "15129/15129 [==============================] - 1s 44us/sample - loss: 53419477101.2429 - val_loss: 46274225568.2961\n",
      "Epoch 245/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 54010197861.8145 - val_loss: 46326505123.2967\n",
      "Epoch 246/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 54753348964.0886 - val_loss: 46211938694.3960\n",
      "Epoch 247/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 54253930390.6828 - val_loss: 46201641001.6928\n",
      "Epoch 248/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53792825322.8824 - val_loss: 46209220587.7853\n",
      "Epoch 249/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54301513228.8939 - val_loss: 46146570764.3183\n",
      "Epoch 250/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53215242691.3208 - val_loss: 46076352351.5460\n",
      "Epoch 251/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 53696239804.0278 - val_loss: 46102694346.6206\n",
      "Epoch 252/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 53983862572.0119 - val_loss: 46046860494.5688\n",
      "Epoch 253/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 56039903398.1656 - val_loss: 46099595162.9266\n",
      "Epoch 254/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 52907431494.8319 - val_loss: 46046256828.5651\n",
      "Epoch 255/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 53168111073.1697 - val_loss: 46012074073.7027\n",
      "Epoch 256/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 53839170548.1552 - val_loss: 46060435416.8341\n",
      "Epoch 257/1000\n",
      "15129/15129 [==============================] - 1s 50us/sample - loss: 54006113904.7963 - val_loss: 45931557119.2104\n",
      "Epoch 258/1000\n",
      "15129/15129 [==============================] - 1s 51us/sample - loss: 54482644703.3930 - val_loss: 45865750247.5213\n",
      "Epoch 259/1000\n",
      "15129/15129 [==============================] - 1s 55us/sample - loss: 55085412679.8641 - val_loss: 45973769024.5922\n",
      "Epoch 260/1000\n",
      "15129/15129 [==============================] - 1s 53us/sample - loss: 54320411893.8981 - val_loss: 46057375500.1604\n",
      "Epoch 261/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 53850149166.3470 - val_loss: 45714194831.2400\n",
      "Epoch 262/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 54695395186.9453 - val_loss: 45868695193.1894\n",
      "Epoch 263/1000\n",
      "15129/15129 [==============================] - 1s 50us/sample - loss: 55451506677.3058 - val_loss: 45987925674.8772\n",
      "Epoch 264/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 53451546271.4987 - val_loss: 45794576241.2338\n",
      "Epoch 265/1000\n",
      "15129/15129 [==============================] - 1s 52us/sample - loss: 53058857446.7875 - val_loss: 45828544796.2690\n",
      "Epoch 266/1000\n",
      "15129/15129 [==============================] - 1s 50us/sample - loss: 54453607498.2500 - val_loss: 45831390760.7452\n",
      "Epoch 267/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 52622096146.8332 - val_loss: 45783032298.2060\n",
      "Epoch 268/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 54282079458.6757 - val_loss: 45777191498.2258\n",
      "Epoch 269/1000\n",
      "15129/15129 [==============================] - 1s 44us/sample - loss: 54691770825.8185 - val_loss: 45618432857.8606\n",
      "Epoch 270/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 53937340899.2679 - val_loss: 45750655048.0148\n",
      "Epoch 271/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 52874096216.8360 - val_loss: 45548753414.0012\n",
      "Epoch 272/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53417088938.8528 - val_loss: 45563427388.3282\n",
      "Epoch 273/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 55422113517.0652 - val_loss: 45505315129.3276\n",
      "Epoch 274/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53351241730.9781 - val_loss: 45443769815.8865\n",
      "Epoch 275/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 53132387869.8151 - val_loss: 45335659324.8020\n",
      "Epoch 276/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 52757146121.0359 - val_loss: 45451167287.9062\n",
      "Epoch 277/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53785042081.9692 - val_loss: 45333051479.1758\n",
      "Epoch 278/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 54162639105.3368 - val_loss: 45292502236.4664\n",
      "Epoch 279/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 53396533222.9567 - val_loss: 45125143532.4170\n",
      "Epoch 280/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 55999007649.5800 - val_loss: 45281066002.3196\n",
      "Epoch 281/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 54861331549.3370 - val_loss: 45304359830.5046\n",
      "Epoch 282/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 53133507462.2354 - val_loss: 45200188594.7736\n",
      "Epoch 283/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 52022406540.9701 - val_loss: 45131346872.6169\n",
      "Epoch 284/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53109085066.1611 - val_loss: 45198775891.7014\n",
      "Epoch 285/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53241507320.1824 - val_loss: 45072998576.8785\n",
      "Epoch 286/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 53798019867.0231 - val_loss: 44930080934.7711\n",
      "Epoch 287/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 54541454315.7623 - val_loss: 45042022916.7378\n",
      "Epoch 288/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 52988412375.0847 - val_loss: 45059914229.5768\n",
      "Epoch 289/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 52838652193.2839 - val_loss: 44854963422.9932\n",
      "Epoch 290/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 53332625738.0300 - val_loss: 44842100320.3356\n",
      "Epoch 291/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51918708047.2417 - val_loss: 44738015098.0777\n",
      "Epoch 292/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53227263095.8694 - val_loss: 44729100893.1770\n",
      "Epoch 293/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 52534855326.0097 - val_loss: 44782923136.7107\n",
      "Epoch 294/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51084906580.1996 - val_loss: 44698413666.2307\n",
      "Epoch 295/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 53386163450.0945 - val_loss: 44589499975.0672\n",
      "Epoch 296/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53774261843.6920 - val_loss: 44720018390.9389\n",
      "Epoch 297/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 52414979796.5634 - val_loss: 44584204673.3424\n",
      "Epoch 298/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 53289744369.5155 - val_loss: 44573445944.3800\n",
      "Epoch 299/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 52114999625.0824 - val_loss: 44448471283.8396\n",
      "Epoch 300/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 50911625674.9014 - val_loss: 44240579493.6656\n",
      "Epoch 301/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 52198568352.9370 - val_loss: 44437343177.0413\n",
      "Epoch 302/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 52634434122.4192 - val_loss: 44368121176.2813\n",
      "Epoch 303/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 52459510837.4031 - val_loss: 44381053574.8698\n",
      "Epoch 304/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 52224022484.8172 - val_loss: 44202742591.3288\n",
      "Epoch 305/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 51602960207.4786 - val_loss: 44259187710.1049\n",
      "Epoch 306/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 51883751137.6942 - val_loss: 44228388928.4343\n",
      "Epoch 307/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 52459516762.2405 - val_loss: 44217444578.1518\n",
      "Epoch 308/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 51637434384.3797 - val_loss: 44090554222.7070\n",
      "Epoch 309/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 52082593460.6163 - val_loss: 44158493662.5194\n",
      "Epoch 310/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 52751999436.7966 - val_loss: 43963572087.5509\n",
      "Epoch 311/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 52078018906.0036 - val_loss: 43952757161.7717\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 37us/sample - loss: 51978770953.5774 - val_loss: 43929310990.6872\n",
      "Epoch 313/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 52271988821.5533 - val_loss: 44011518322.1814\n",
      "Epoch 314/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 52249479422.9001 - val_loss: 43839362456.7156\n",
      "Epoch 315/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 51414726731.4006 - val_loss: 43778852640.3751\n",
      "Epoch 316/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 52836514282.4425 - val_loss: 43793189388.3183\n",
      "Epoch 317/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51368297564.1187 - val_loss: 43656114537.3374\n",
      "Epoch 318/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51600476565.9721 - val_loss: 43599141229.1277\n",
      "Epoch 319/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 51846435212.2255 - val_loss: 43556061578.1863\n",
      "Epoch 320/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51027465608.0968 - val_loss: 43464367390.1641\n",
      "Epoch 321/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 53372474826.8338 - val_loss: 43614621476.1653\n",
      "Epoch 322/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 50828145652.6967 - val_loss: 43450688367.3387\n",
      "Epoch 323/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 51119899026.8586 - val_loss: 43428959943.9358\n",
      "Epoch 324/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 50501903909.8018 - val_loss: 43233196543.6841\n",
      "Epoch 325/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 52491302226.6259 - val_loss: 43579607058.9513\n",
      "Epoch 326/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 50854784334.1588 - val_loss: 43266101801.3769\n",
      "Epoch 327/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 52881536551.4263 - val_loss: 43236354233.7224\n",
      "Epoch 328/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 50338980644.3635 - val_loss: 43266863935.3288\n",
      "Epoch 329/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 53032536113.9512 - val_loss: 43397064687.5756\n",
      "Epoch 330/1000\n",
      "15129/15129 [==============================] - 1s 43us/sample - loss: 52711107025.5345 - val_loss: 43356415286.1690\n",
      "Epoch 331/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 53835795270.6119 - val_loss: 43095320039.0475\n",
      "Epoch 332/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 52528280907.4514 - val_loss: 43143223059.7409\n",
      "Epoch 333/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51833013307.7655 - val_loss: 43099867362.1518\n",
      "Epoch 334/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 51207407430.5443 - val_loss: 43105950697.8902\n",
      "Epoch 335/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 51851285573.6474 - val_loss: 43009775086.6280\n",
      "Epoch 336/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 51023313031.4368 - val_loss: 42936604592.4047\n",
      "Epoch 337/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 50302870756.5708 - val_loss: 42893072541.9272\n",
      "Epoch 338/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 51405367137.9565 - val_loss: 42833568123.0253\n",
      "Epoch 339/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 50479216271.1867 - val_loss: 42961250105.6434\n",
      "Epoch 340/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 51836275821.8521 - val_loss: 42784937606.2381\n",
      "Epoch 341/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 50231676479.9281 - val_loss: 42723836914.7341\n",
      "Epoch 342/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 50920610426.7460 - val_loss: 42746877119.4078\n",
      "Epoch 343/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 51122044979.9818 - val_loss: 42740619922.2406\n",
      "Epoch 344/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 49130600921.9274 - val_loss: 42827692685.1869\n",
      "Epoch 345/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 50402908189.9166 - val_loss: 42719455912.9821\n",
      "Epoch 346/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 49895361588.3202 - val_loss: 42640113082.8279\n",
      "Epoch 347/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 51829107380.9547 - val_loss: 42449912929.9149\n",
      "Epoch 348/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 50736891646.1217 - val_loss: 42576224710.8304\n",
      "Epoch 349/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 51825346924.1430 - val_loss: 42547003599.2005\n",
      "Epoch 350/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 50348072089.8470 - val_loss: 42614324671.8816\n",
      "Epoch 351/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 50089506432.2284 - val_loss: 42461821343.6644\n",
      "Epoch 352/1000\n",
      "15129/15129 [==============================] - 1s 44us/sample - loss: 49686746062.6579 - val_loss: 42553977416.9624\n",
      "Epoch 353/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 51061514440.7525 - val_loss: 42651921853.3547\n",
      "Epoch 354/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 50354167154.4377 - val_loss: 42395299599.9506\n",
      "Epoch 355/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 50522399166.1767 - val_loss: 42216083751.6397\n",
      "Epoch 356/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 50675125538.4345 - val_loss: 42227938803.6817\n",
      "Epoch 357/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 50402403559.4136 - val_loss: 42227708962.7440\n",
      "Epoch 358/1000\n",
      "15129/15129 [==============================] - 1s 45us/sample - loss: 52080301539.4709 - val_loss: 42177463282.7341\n",
      "Epoch 359/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 51373023050.8761 - val_loss: 42080535634.7539\n",
      "Epoch 360/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 50277581563.2113 - val_loss: 42065049358.6872\n",
      "Epoch 361/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 49451800090.7016 - val_loss: 42092602728.7057\n",
      "Epoch 362/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 50231276197.5226 - val_loss: 42113378651.4398\n",
      "Epoch 363/1000\n",
      "15129/15129 [==============================] - 1s 42us/sample - loss: 52145733906.0549 - val_loss: 41997762509.4633\n",
      "Epoch 364/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 50989867428.9981 - val_loss: 42022680905.7520\n",
      "Epoch 365/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 49672121417.9792 - val_loss: 41788556840.7452\n",
      "Epoch 366/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 48949732333.2514 - val_loss: 41834124474.3541\n",
      "Epoch 367/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 49237173887.6870 - val_loss: 41774292789.8532\n",
      "Epoch 368/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 49404219852.2551 - val_loss: 41800383228.3677\n",
      "Epoch 369/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 50160502952.5346 - val_loss: 41690158827.3115\n",
      "Epoch 370/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 49020607729.5663 - val_loss: 41732972099.2770\n",
      "Epoch 371/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 50392976677.4127 - val_loss: 41648498833.2930\n",
      "Epoch 372/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 50226824191.1201 - val_loss: 41538687822.4898\n",
      "Epoch 373/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 50180982690.8660 - val_loss: 41579434552.5379\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 35us/sample - loss: 50584380086.7145 - val_loss: 41428668145.6286\n",
      "Epoch 375/1000\n",
      "15129/15129 [==============================] - 1s 43us/sample - loss: 48523583943.3818 - val_loss: 41369290472.7847\n",
      "Epoch 376/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 51372748128.5690 - val_loss: 41569909712.6218\n",
      "Epoch 377/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 47120737550.1292 - val_loss: 41435265510.4158\n",
      "Epoch 378/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 49921844344.0048 - val_loss: 41298540226.8822\n",
      "Epoch 379/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 48100765938.1754 - val_loss: 41442631432.3701\n",
      "Epoch 380/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 50000023774.5469 - val_loss: 41344877974.1888\n",
      "Epoch 381/1000\n",
      "15129/15129 [==============================] - 1s 53us/sample - loss: 48588857386.3705 - val_loss: 41219655097.5645\n",
      "Epoch 382/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 50520862724.0611 - val_loss: 41152105017.8014\n",
      "Epoch 383/1000\n",
      "15129/15129 [==============================] - 1s 45us/sample - loss: 50113702342.5696 - val_loss: 41165949659.5188\n",
      "Epoch 384/1000\n",
      "15129/15129 [==============================] - 1s 51us/sample - loss: 49884949362.0654 - val_loss: 41195753191.5213\n",
      "Epoch 385/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 50130725114.5683 - val_loss: 41122586755.3954\n",
      "Epoch 386/1000\n",
      "15129/15129 [==============================] - 1s 52us/sample - loss: 47879341679.1719 - val_loss: 41124737243.8347\n",
      "Epoch 387/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 48687241405.6522 - val_loss: 41086248625.1943\n",
      "Epoch 388/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 50321047175.9445 - val_loss: 41052423457.9543\n",
      "Epoch 389/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 50046702655.5558 - val_loss: 41086766520.3010\n",
      "Epoch 390/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 50173198011.6555 - val_loss: 40931409374.2036\n",
      "Epoch 391/1000\n",
      "15129/15129 [==============================] - 1s 42us/sample - loss: 48481589746.5646 - val_loss: 40850572598.1690\n",
      "Epoch 392/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 49368689609.3785 - val_loss: 40968304176.3257\n",
      "Epoch 393/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 48456837143.2835 - val_loss: 40889304601.5842\n",
      "Epoch 394/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 50904651440.5552 - val_loss: 40717929361.4510\n",
      "Epoch 395/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 49132340676.6068 - val_loss: 40705137818.7687\n",
      "Epoch 396/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 48685410959.3221 - val_loss: 40715491960.9722\n",
      "Epoch 397/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47729221078.0694 - val_loss: 40697320179.5238\n",
      "Epoch 398/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48361585828.6766 - val_loss: 40607221703.1462\n",
      "Epoch 399/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 48339030407.6230 - val_loss: 40683789623.4324\n",
      "Epoch 400/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 48558562450.6725 - val_loss: 40546840148.9648\n",
      "Epoch 401/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 49737933307.0929 - val_loss: 40516689475.2770\n",
      "Epoch 402/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 48026972208.3268 - val_loss: 40565608713.3177\n",
      "Epoch 403/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 47601711215.1381 - val_loss: 40453205730.4676\n",
      "Epoch 404/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 47576636502.4332 - val_loss: 40577596980.1160\n",
      "Epoch 405/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 48302289962.8443 - val_loss: 40528157102.8254\n",
      "Epoch 406/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 48474305645.5813 - val_loss: 40528882289.3917\n",
      "Epoch 407/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 49023285626.0861 - val_loss: 40370429532.5453\n",
      "Epoch 408/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 49848542074.8644 - val_loss: 40266046366.0851\n",
      "Epoch 409/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 47513668052.1065 - val_loss: 40411601291.4497\n",
      "Epoch 410/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 47640807037.9272 - val_loss: 40262771309.6015\n",
      "Epoch 411/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47617168838.9081 - val_loss: 40297460113.7668\n",
      "Epoch 412/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48231166977.0830 - val_loss: 40305448587.2918\n",
      "Epoch 413/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 47971809205.4116 - val_loss: 40145753941.4386\n",
      "Epoch 414/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 48705580498.9559 - val_loss: 40086467689.4954\n",
      "Epoch 415/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 48064565806.5331 - val_loss: 40206750229.1622\n",
      "Epoch 416/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 48761489372.6687 - val_loss: 40191234055.5805\n",
      "Epoch 417/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 50006910983.4453 - val_loss: 40137559566.2134\n",
      "Epoch 418/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 49230681544.1264 - val_loss: 40119525562.9858\n",
      "Epoch 419/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 48661387511.3195 - val_loss: 40009427220.6885\n",
      "Epoch 420/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 47775724924.8611 - val_loss: 39950344944.9969\n",
      "Epoch 421/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47867035626.6117 - val_loss: 40110828524.4170\n",
      "Epoch 422/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 47511641819.6026 - val_loss: 39986493618.1419\n",
      "Epoch 423/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 48972370660.7400 - val_loss: 40103857091.9877\n",
      "Epoch 424/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 47125231877.6686 - val_loss: 39887437005.3054\n",
      "Epoch 425/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 49310159215.9334 - val_loss: 39846534561.5595\n",
      "Epoch 426/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47233245894.8235 - val_loss: 39686795817.3769\n",
      "Epoch 427/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48059777949.6543 - val_loss: 39686272545.1647\n",
      "Epoch 428/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47655665154.1321 - val_loss: 39904595758.2727\n",
      "Epoch 429/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48178006675.3832 - val_loss: 39586915279.3584\n",
      "Epoch 430/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 47926076037.6432 - val_loss: 39675683169.7569\n",
      "Epoch 431/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 49118718886.8594 - val_loss: 39625617107.3066\n",
      "Epoch 432/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47637175756.8643 - val_loss: 39565103940.3825\n",
      "Epoch 433/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48363890458.8200 - val_loss: 39636653419.2326\n",
      "Epoch 434/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 48223774833.0332 - val_loss: 39627742281.9099\n",
      "Epoch 435/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46647012293.3175 - val_loss: 39555181821.3152\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46737915928.0957 - val_loss: 39593459944.4688\n",
      "Epoch 437/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46784016269.2069 - val_loss: 39459274686.3023\n",
      "Epoch 438/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47321628013.2937 - val_loss: 39403652992.3948\n",
      "Epoch 439/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48596772181.6041 - val_loss: 39379362635.9630\n",
      "Epoch 440/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47648521685.6633 - val_loss: 39463510465.7767\n",
      "Epoch 441/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46698385335.7129 - val_loss: 39307486467.6323\n",
      "Epoch 442/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 47098036315.6449 - val_loss: 39413251676.5453\n",
      "Epoch 443/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 48236332989.8045 - val_loss: 39331104468.5700\n",
      "Epoch 444/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 48326901573.4613 - val_loss: 39404723678.2036\n",
      "Epoch 445/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 47142668949.0076 - val_loss: 39284115520.4343\n",
      "Epoch 446/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 47580056933.1715 - val_loss: 39296066465.8754\n",
      "Epoch 447/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45645820995.0754 - val_loss: 39216833492.4121\n",
      "Epoch 448/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 48117488102.9229 - val_loss: 39229814759.9951\n",
      "Epoch 449/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47224533490.9707 - val_loss: 39263487361.9741\n",
      "Epoch 450/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 49079673153.9079 - val_loss: 39308481823.4275\n",
      "Epoch 451/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 46800433219.6846 - val_loss: 39268390296.7156\n",
      "Epoch 452/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 48207191779.7248 - val_loss: 39257499965.1178\n",
      "Epoch 453/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 47346903394.5318 - val_loss: 39171666741.2215\n",
      "Epoch 454/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 47615143024.9656 - val_loss: 39221630946.9414\n",
      "Epoch 455/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46389158389.2043 - val_loss: 39083409579.8248\n",
      "Epoch 456/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 46779407454.2846 - val_loss: 39118322337.4016\n",
      "Epoch 457/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47202401483.5275 - val_loss: 38970260321.4411\n",
      "Epoch 458/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46903223338.9797 - val_loss: 38914496194.8822\n",
      "Epoch 459/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 46462253811.3599 - val_loss: 39014345587.1289\n",
      "Epoch 460/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 46141398353.0015 - val_loss: 38872983505.2535\n",
      "Epoch 461/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45780271386.6508 - val_loss: 38834507460.1456\n",
      "Epoch 462/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47073855493.2794 - val_loss: 38812747769.6829\n",
      "Epoch 463/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 46355232290.2822 - val_loss: 39002177935.2400\n",
      "Epoch 464/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47743369405.6522 - val_loss: 38958945708.9303\n",
      "Epoch 465/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47274166448.9275 - val_loss: 38697615865.3671\n",
      "Epoch 466/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 44727535939.1262 - val_loss: 38729569890.8624\n",
      "Epoch 467/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 44517149183.0186 - val_loss: 38713279777.9543\n",
      "Epoch 468/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 45988837070.7426 - val_loss: 38921773020.6243\n",
      "Epoch 469/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46731249313.5293 - val_loss: 38790876665.9988\n",
      "Epoch 470/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47576788245.5745 - val_loss: 38587343636.3726\n",
      "Epoch 471/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46733926697.4060 - val_loss: 38762578021.0734\n",
      "Epoch 472/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46777299522.8385 - val_loss: 38696334446.5490\n",
      "Epoch 473/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47432104046.0551 - val_loss: 38653439416.3010\n",
      "Epoch 474/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 47428813293.5560 - val_loss: 38582138532.5602\n",
      "Epoch 475/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 45895498084.6977 - val_loss: 38519508473.9988\n",
      "Epoch 476/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 48195979543.2666 - val_loss: 38593738657.2437\n",
      "Epoch 477/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47663587934.4538 - val_loss: 38646469019.8742\n",
      "Epoch 478/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47317043295.9090 - val_loss: 38585434743.7088\n",
      "Epoch 479/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 45961887026.9496 - val_loss: 38486678728.2517\n",
      "Epoch 480/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 47483291865.5382 - val_loss: 38547686275.5534\n",
      "Epoch 481/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 47367612563.1463 - val_loss: 38483129060.3627\n",
      "Epoch 482/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 47186547511.8567 - val_loss: 38555771612.7822\n",
      "Epoch 483/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45919745728.9349 - val_loss: 38446982782.6576\n",
      "Epoch 484/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45902302039.3977 - val_loss: 38518241003.3115\n",
      "Epoch 485/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47332019009.3325 - val_loss: 38436469990.5737\n",
      "Epoch 486/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 46557681175.4527 - val_loss: 38352668640.4146\n",
      "Epoch 487/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45793288810.0956 - val_loss: 38404835943.2844\n",
      "Epoch 488/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 47679011246.0678 - val_loss: 38328932823.2548\n",
      "Epoch 489/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47662532686.6495 - val_loss: 38346639747.8692\n",
      "Epoch 490/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 46661904528.7096 - val_loss: 38379324417.8951\n",
      "Epoch 491/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46202847325.6755 - val_loss: 38184719844.5207\n",
      "Epoch 492/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45942929064.2977 - val_loss: 38245050796.2986\n",
      "Epoch 493/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45891631813.8759 - val_loss: 38202417490.5959\n",
      "Epoch 494/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46471604971.3731 - val_loss: 38186286234.7687\n",
      "Epoch 495/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46437090182.9123 - val_loss: 38135872985.1499\n",
      "Epoch 496/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 45627625024.3342 - val_loss: 38057215028.4318\n",
      "Epoch 497/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45514142457.0454 - val_loss: 38057366845.7495\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44860024579.8073 - val_loss: 38006266408.1135\n",
      "Epoch 499/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47206864275.3324 - val_loss: 38132937070.3911\n",
      "Epoch 500/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 47423335734.3338 - val_loss: 38291729807.8717\n",
      "Epoch 501/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46719908313.1152 - val_loss: 38119575008.7304\n",
      "Epoch 502/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 45846869899.3118 - val_loss: 38100865734.0407\n",
      "Epoch 503/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 47533067082.5376 - val_loss: 37958248800.4935\n",
      "Epoch 504/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 44563523321.5192 - val_loss: 37970095923.3263\n",
      "Epoch 505/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 46210910187.2885 - val_loss: 37912948435.3066\n",
      "Epoch 506/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 45676929432.2734 - val_loss: 37957011070.6576\n",
      "Epoch 507/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 45556505973.2805 - val_loss: 37950545834.0876\n",
      "Epoch 508/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 45287830812.8844 - val_loss: 37982831102.4207\n",
      "Epoch 509/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 47807487493.1779 - val_loss: 38034824948.1555\n",
      "Epoch 510/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 45606162960.2105 - val_loss: 38046466538.2060\n",
      "Epoch 511/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 44693207776.2729 - val_loss: 37956492836.9550\n",
      "Epoch 512/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 46145623296.3215 - val_loss: 37837482836.8069\n",
      "Epoch 513/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45498395365.5522 - val_loss: 37839082247.7384\n",
      "Epoch 514/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45918782715.7189 - val_loss: 37812163421.6508\n",
      "Epoch 515/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 46673896185.1808 - val_loss: 37816557199.0820\n",
      "Epoch 516/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45914719207.9043 - val_loss: 37696807119.2005\n",
      "Epoch 517/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45795034027.1912 - val_loss: 37812069276.8217\n",
      "Epoch 518/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 45747444219.2282 - val_loss: 37884745966.7859\n",
      "Epoch 519/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46509696662.3613 - val_loss: 37756796276.0765\n",
      "Epoch 520/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 46787165311.0440 - val_loss: 37961513390.8254\n",
      "Epoch 521/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46939836443.3446 - val_loss: 37798463784.9031\n",
      "Epoch 522/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45380063438.4380 - val_loss: 37638727244.1209\n",
      "Epoch 523/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46694739382.3930 - val_loss: 37715598551.4127\n",
      "Epoch 524/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 45730181300.8532 - val_loss: 37814885869.3646\n",
      "Epoch 525/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45820099334.4470 - val_loss: 37633089748.2542\n",
      "Epoch 526/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44690391362.1786 - val_loss: 37617005213.6114\n",
      "Epoch 527/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45721868817.9703 - val_loss: 37599490763.0944\n",
      "Epoch 528/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 44788446721.6583 - val_loss: 37587524803.1980\n",
      "Epoch 529/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44896712074.1273 - val_loss: 37517581446.5540\n",
      "Epoch 530/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46783319181.1223 - val_loss: 37423440710.9093\n",
      "Epoch 531/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 44933730559.8477 - val_loss: 37530237869.2461\n",
      "Epoch 532/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45313004758.4924 - val_loss: 37624306549.6558\n",
      "Epoch 533/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 47722503553.8698 - val_loss: 37613445478.8106\n",
      "Epoch 534/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45351973288.2469 - val_loss: 37522647357.1178\n",
      "Epoch 535/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45628296283.3065 - val_loss: 37591884579.5336\n",
      "Epoch 536/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45785385305.8682 - val_loss: 37535639111.0672\n",
      "Epoch 537/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 47112790461.7706 - val_loss: 37460674503.1462\n",
      "Epoch 538/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46208020156.1970 - val_loss: 37378675312.1283\n",
      "Epoch 539/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45961790984.0206 - val_loss: 37525209062.7316\n",
      "Epoch 540/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45875634052.0018 - val_loss: 37377478855.6200\n",
      "Epoch 541/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44604779989.7310 - val_loss: 37324477479.7977\n",
      "Epoch 542/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45967422103.1735 - val_loss: 37386332391.2054\n",
      "Epoch 543/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45383973862.8890 - val_loss: 37324686833.1548\n",
      "Epoch 544/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45485918014.8282 - val_loss: 37366873692.5453\n",
      "Epoch 545/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 45706160259.4435 - val_loss: 37357818874.3146\n",
      "Epoch 546/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45778012709.1927 - val_loss: 37311027130.5120\n",
      "Epoch 547/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44948922724.2916 - val_loss: 37197687283.0500\n",
      "Epoch 548/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45532285979.1415 - val_loss: 37226539117.9173\n",
      "Epoch 549/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 47818642855.9085 - val_loss: 37249184903.8174\n",
      "Epoch 550/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45822363950.2793 - val_loss: 37099951164.0123\n",
      "Epoch 551/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44240467680.0698 - val_loss: 37255785871.8717\n",
      "Epoch 552/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45697158410.7449 - val_loss: 37156271027.5632\n",
      "Epoch 553/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44481201463.8229 - val_loss: 37127284694.3072\n",
      "Epoch 554/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44040743372.9320 - val_loss: 37113235909.5669\n",
      "Epoch 555/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46141951558.1551 - val_loss: 37197572483.8692\n",
      "Epoch 556/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45415750505.1311 - val_loss: 37030925255.7779\n",
      "Epoch 557/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44744218765.4608 - val_loss: 37138036747.3708\n",
      "Epoch 558/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 44727843811.0987 - val_loss: 37175328020.0568\n",
      "Epoch 559/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45129806598.0408 - val_loss: 37047777341.9075\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 35us/sample - loss: 45942090202.7396 - val_loss: 37091453331.0302\n",
      "Epoch 561/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45079717206.9578 - val_loss: 37006354577.2930\n",
      "Epoch 562/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45320109773.7950 - val_loss: 37101022188.4170\n",
      "Epoch 563/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46196213555.7279 - val_loss: 37028794087.5213\n",
      "Epoch 564/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45098235807.3464 - val_loss: 37050762641.1351\n",
      "Epoch 565/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 45278564672.8926 - val_loss: 36986836447.4670\n",
      "Epoch 566/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 44926471384.3876 - val_loss: 37050410971.3609\n",
      "Epoch 567/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 43884021681.3505 - val_loss: 36955190529.1055\n",
      "Epoch 568/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45981545024.9434 - val_loss: 36988332505.7816\n",
      "Epoch 569/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44123337599.6023 - val_loss: 36901525353.6533\n",
      "Epoch 570/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44367057793.9036 - val_loss: 36846712570.4725\n",
      "Epoch 571/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 44918101032.2723 - val_loss: 36922717041.8655\n",
      "Epoch 572/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 45272196342.3042 - val_loss: 36856476383.3091\n",
      "Epoch 573/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 45427373197.2577 - val_loss: 36861968560.8785\n",
      "Epoch 574/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 45492635294.8219 - val_loss: 36762395756.0222\n",
      "Epoch 575/1000\n",
      "15129/15129 [==============================] - 1s 33us/sample - loss: 47436848236.3630 - val_loss: 36845811657.6730\n",
      "Epoch 576/1000\n",
      "15129/15129 [==============================] - 0s 30us/sample - loss: 44838706283.9569 - val_loss: 36865910009.5250\n",
      "Epoch 577/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 46083580863.0905 - val_loss: 36714725305.2486\n",
      "Epoch 578/1000\n",
      "15129/15129 [==============================] - 0s 31us/sample - loss: 44691444145.9935 - val_loss: 36846838750.5194\n",
      "Epoch 579/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 46217785989.5078 - val_loss: 36718542949.0734\n",
      "Epoch 580/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 47030539938.3415 - val_loss: 36884484998.0802\n",
      "Epoch 581/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 44688829899.5106 - val_loss: 36778633967.7335\n",
      "Epoch 582/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45191290453.8579 - val_loss: 36772400345.9395\n",
      "Epoch 583/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 46176710350.6072 - val_loss: 36831312499.9186\n",
      "Epoch 584/1000\n",
      "15129/15129 [==============================] - 1s 47us/sample - loss: 45233708776.0566 - val_loss: 36759882085.5472\n",
      "Epoch 585/1000\n",
      "15129/15129 [==============================] - 1s 49us/sample - loss: 43433354928.1491 - val_loss: 36638317505.4608\n",
      "Epoch 586/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 45422702101.6929 - val_loss: 36728483337.1598\n",
      "Epoch 587/1000\n",
      "15129/15129 [==============================] - 1s 40us/sample - loss: 45211955216.2443 - val_loss: 36662623361.5003\n",
      "Epoch 588/1000\n",
      "15129/15129 [==============================] - 1s 39us/sample - loss: 46816221101.2894 - val_loss: 36754807467.5089\n",
      "Epoch 589/1000\n",
      "15129/15129 [==============================] - 1s 42us/sample - loss: 45724234669.3571 - val_loss: 36644787659.2523\n",
      "Epoch 590/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 44063263540.6078 - val_loss: 36641507867.4793\n",
      "Epoch 591/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 44963690360.2247 - val_loss: 36588329724.3677\n",
      "Epoch 592/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 44612744667.2134 - val_loss: 36659206185.6928\n",
      "Epoch 593/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45525091419.9833 - val_loss: 36783357815.5509\n",
      "Epoch 594/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45032744554.7047 - val_loss: 36581737574.9685\n",
      "Epoch 595/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44794284956.1652 - val_loss: 36638880049.7471\n",
      "Epoch 596/1000\n",
      "15129/15129 [==============================] - 1s 45us/sample - loss: 45812582575.8445 - val_loss: 36564489518.5885\n",
      "Epoch 597/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 43112288143.9143 - val_loss: 36591335298.9217\n",
      "Epoch 598/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 45324639346.7254 - val_loss: 36579745291.6866\n",
      "Epoch 599/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 44586683311.6584 - val_loss: 36654883144.4886\n",
      "Epoch 600/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 44619349426.8734 - val_loss: 36430943509.3202\n",
      "Epoch 601/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44252347639.2518 - val_loss: 36538921922.7242\n",
      "Epoch 602/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44074758050.3245 - val_loss: 36397365037.0093\n",
      "Epoch 603/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 46082549104.6102 - val_loss: 36390767025.3522\n",
      "Epoch 604/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44455246633.1015 - val_loss: 36419200209.0956\n",
      "Epoch 605/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45345743388.5291 - val_loss: 36448181145.0315\n",
      "Epoch 606/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 44700766843.5582 - val_loss: 36402497342.6971\n",
      "Epoch 607/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45052072299.8723 - val_loss: 36546256314.8279\n",
      "Epoch 608/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 46494264726.0398 - val_loss: 36443728987.5978\n",
      "Epoch 609/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 46113613007.3179 - val_loss: 36390366602.8180\n",
      "Epoch 610/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 44788138075.6449 - val_loss: 36328041310.9143\n",
      "Epoch 611/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 43587265603.3462 - val_loss: 36236765539.0204\n",
      "Epoch 612/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 43362408353.6477 - val_loss: 36266110632.3504\n",
      "Epoch 613/1000\n",
      "15129/15129 [==============================] - 1s 38us/sample - loss: 44040478551.3300 - val_loss: 36455134874.4528\n",
      "Epoch 614/1000\n",
      "15129/15129 [==============================] - 1s 35us/sample - loss: 46865196253.4639 - val_loss: 36423049721.3671\n",
      "Epoch 615/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44345066248.0714 - val_loss: 36292108717.5620\n",
      "Epoch 616/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 44164776071.6399 - val_loss: 36231965552.6021\n",
      "Epoch 617/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 43164109234.1289 - val_loss: 36401705250.5861\n",
      "Epoch 618/1000\n",
      "15129/15129 [==============================] - 0s 33us/sample - loss: 44149440743.2105 - val_loss: 36237718941.7693\n",
      "Epoch 619/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 45009415456.6747 - val_loss: 36153706092.9698\n",
      "Epoch 620/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45022614015.1539 - val_loss: 36143090478.9044\n",
      "Epoch 621/1000\n",
      "15129/15129 [==============================] - 1s 37us/sample - loss: 43577670059.6312 - val_loss: 36049085841.1351\n",
      "Epoch 622/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15129/15129 [==============================] - 1s 34us/sample - loss: 44076363679.4818 - val_loss: 36202356687.9901\n",
      "Epoch 623/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 43217150164.8003 - val_loss: 36235269126.9488\n",
      "Epoch 624/1000\n",
      "15129/15129 [==============================] - 0s 32us/sample - loss: 43504916353.9713 - val_loss: 36180573189.6854\n",
      "Epoch 625/1000\n",
      "15129/15129 [==============================] - 1s 36us/sample - loss: 45026414303.6637 - val_loss: 36161564525.4436\n",
      "Epoch 626/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 43539590383.8065 - val_loss: 36171496489.0611\n",
      "Epoch 627/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 44560486037.7521 - val_loss: 36150754448.6613\n",
      "Epoch 628/1000\n",
      "15129/15129 [==============================] - 1s 45us/sample - loss: 46255579492.2916 - val_loss: 36420363068.8020\n",
      "Epoch 629/1000\n",
      "15129/15129 [==============================] - 1s 42us/sample - loss: 46477261281.2374 - val_loss: 36187075929.5447\n",
      "Epoch 630/1000\n",
      "15129/15129 [==============================] - 1s 34us/sample - loss: 42010274819.4519 - val_loss: 36239278949.2313\n",
      "Epoch 631/1000\n",
      "15129/15129 [==============================] - 1s 41us/sample - loss: 46255228167.9022 - val_loss: 36241577626.4528\n",
      "Epoch 00631: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb586f31d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=1000, verbose=1, callbacks=[early_stop], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "JiXlIakGEkBJ",
    "outputId": "01cdb79b-b445-4f11-f052-fbca6e3d0306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffb35331810>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hao8noOhFtni"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipQuwuPkI9PZ"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NAZ_0yobJCys",
    "outputId": "6afb0218-e1e7-4281-9ff5-fff0450efef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190372.20764850307"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VyiAr331JJw1",
    "outputId": "7f4f88e6-8593-4997-d94b-33a26e8ad87d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114471.69960395676"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "sA5cPfETJSLC",
    "outputId": "b089993f-926d-41c6-fe05-57808bf9b90d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.161300e+04\n",
       "mean     5.400881e+05\n",
       "std      3.671272e+05\n",
       "min      7.500000e+04\n",
       "25%      3.219500e+05\n",
       "50%      4.500000e+05\n",
       "75%      6.450000e+05\n",
       "max      7.700000e+06\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oqESAaFWJVkM",
    "outputId": "932e5f83-1cb6-4157-fa1a-6bcc6683ea50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540088.1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.400881e+05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KZ8Kyfl-JZYs",
    "outputId": "cd2fd03c-6788-4025-ec5d-1117a836cee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752517853138752"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crapC71aJha7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Regression kc housing dataset",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
